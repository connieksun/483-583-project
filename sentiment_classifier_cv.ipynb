{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import json\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # annotated data directory\n",
    "# annotated_data = \"/home/u32/cchyland/iBelieveFiles/only_uganda_with_triggers\"\n",
    "# # original triggerless data directory\n",
    "# triggerless_original_dir = \"/home/u32/cchyland/iBelieveFiles/triggerless_original/only_uganda\"\n",
    "# # triggerless sample data (change directory for new samples); with header and labeled as \"n\" (non-belief)\n",
    "# triggerless_sample = \"/home/u32/cchyland/iBelieveFiles/triggerless_sample/only_uganda\"\n",
    "# # triggerless samples actually used\n",
    "# triggerless_samples_used = \"/home/u32/cchyland/iBelieveFiles/triggerless_samples_used/only_uganda\"\n",
    "# # save models here (change dir for newly-trained models):\n",
    "# models_dir = \"/xdisk/msurdeanu/cchyland/models\"\n",
    "models_dir = \"models/bert-k-fold\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a sample of triggerless examples to use; if don't have too many, just use all of them (frac = 1.0)\n",
    "# # percentage of triggerless sentences to sample if there are too many triggerless examples available:\n",
    "# frac = 1.0\n",
    "# random_seed = 22\n",
    "\n",
    "# # this is what annotated column is called in the annotated data files---use the same names to assign annotations\n",
    "# # to sampled negative examples:\n",
    "# annotations_column = \"annotation: b (belief or attitude), n (not a belief and not an attitude)\"\n",
    "\n",
    "# # TODO: to experiment with different sizes of triggerless examples, need to sample in some other way because it should\n",
    "# # be based on the number of annotated examples, e.g., 4 times annotated examples;\n",
    "# # could oversample and then sample from there?..\n",
    "# for file in listdir(triggerless_original_dir):\n",
    "#     f_path = os.path.join(triggerless_original_dir, file)\n",
    "#     print(f_path)\n",
    "#     temp_df = pd.read_csv(f_path, sep='\\t', header=None, on_bad_lines=\"skip\")\n",
    "# #     print(temp_df.head())\n",
    "#     print(len(temp_df))\n",
    "#     # naming triggerless docs columns for easier use later\n",
    "#     temp_df.columns = [\"file\", \"na\", \"sentence\", \"trigger\", \"na\", \"paragraph\",\"na\"]\n",
    "#     temp_df[annotations_column] = [\"n\"] * len(temp_df)\n",
    "#     temp_df.sample(frac=frac, random_state = random_seed).reset_index(drop=True).to_csv(os.path.join(triggerless_sample, file), sep=\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotated_data = os.path.join(project_dir, \"annotated_as_of_dec13_both_uganda_and_rice\")\n",
    "# annotated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(os.path.join(annotated_data, \"Subtask1-MainTask-double-annotation-prep-as-of-Nov2.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load annotated data\n",
    "# adf = pd.DataFrame()\n",
    "# for file in listdir(annotated_data):\n",
    "#     print(file)\n",
    "#     if file.endswith(\"tsv\"):\n",
    "#         f_path = os.path.join(annotated_data, file)\n",
    "#         temp_df = pd.read_csv(f_path, sep='\\t', usecols = [\"paragraph\", \"mention text (just a few words around the trigger)\",\"trigger\",\"sentence\",\"annotation: b (belief or attitude), n (not a belief and not an attitude)\"]).dropna()\n",
    "#         print(len(temp_df))\n",
    "#         adf = pd.concat([adf, temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adf[\"sentence\"] = [s.strip() for s in adf[\"sentence\"]]\n",
    "# adf = adf.drop_duplicates(subset = [\"sentence\", \"mention text (just a few words around the trigger)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anns = adf[annotations_column]\n",
    "# b_count = list(anns).count(\"b\")\n",
    "\n",
    "# # percentage of sentences annotated as beliefs (among all annotated)\n",
    "# float(b_count)/len(adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load negative examples sampled\n",
    "# ndf = pd.DataFrame() \n",
    "# for file in listdir(triggerless_sample):\n",
    "#     f_path = os.path.join(triggerless_sample, file)\n",
    "#     temp_df = pd.read_csv(f_path, sep='\\t', usecols = [\"paragraph\",\"trigger\",\"sentence\",annotations_column])\n",
    "# #     print(len(temp_df))\n",
    "#     ndf = pd.concat([ndf, temp_df])\n",
    "    \n",
    "# ndf[\"sentence\"] = [s.strip() for s in ndf[\"sentence\"]]\n",
    "# ndf = ndf.drop_duplicates(subset = [\"sentence\"])\n",
    "# len(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how many times more triggerless data to use compared to trigger-ed examples\n",
    "# # pick the number that is either the amount we want based on the multiplier or if that number is higher than the number\n",
    "# # of available examples, just use all triggerless examples\n",
    "# neg_example_multiplier = 2\n",
    "# n_neg_examples_to_use = min(len(adf) * neg_example_multiplier, len(ndf))\n",
    "# n_neg_examples_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take the neg example sample, write it to a file for record keeping, and read it back in\n",
    "# sample_file_name = os.path.join(triggerless_samples_used, f\"triggerless_sample_{neg_example_multiplier}_times_triggered_size\")\n",
    "# rewrite_sample = True\n",
    "# if path.exists(sample_file_name) and not rewrite_sample:\n",
    "#     print(\"exists\")\n",
    "#     ndf = pd.read_csv(sample_file_name, sep=\"\\t\")\n",
    "# else:\n",
    "#     print(\"new sample\")\n",
    "#     ndf = ndf.sample(n=n_neg_examples_to_use, random_state = random_seed).reset_index(drop=True).to_csv(sample_file_name, index=False, sep=\"\\t\")\n",
    "#     ndf = pd.read_csv(sample_file_name, sep=\"\\t\")\n",
    "    \n",
    "# print(f\"N triggerless examples: {len(ndf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # annotated + sampled triggerless\n",
    "# df = pd.concat([adf, ndf])#.reset_index(drop=True)\n",
    "# print(f\"Annotated + sampled = {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index = [x for x in range(0,len(df.index))]\n",
    "\n",
    "# # Adding markers to trigger\n",
    "# for i in df.index: \n",
    "#    if (not pd.isna(df.at[i,\"trigger\"])): \n",
    "#        triggerText = df.at[i,\"trigger\"]\n",
    "#        df.at[i,\"trigger\"] = df.at[i,\"trigger\"].replace(df.at[i,\"trigger\"], \"<t>\" + df.at[i,\"trigger\"] + \"</t>\")\n",
    "#        df.at[i,\"sentence\"] = df.at[i,\"sentence\"].replace(triggerText, \"<t>\" + triggerText + \"</t>\")\n",
    "#        df.at[i,\"paragraph\"] = df.at[i,\"paragraph\"].replace(triggerText, \"<t>\" + triggerText + \"</t>\")\n",
    "#        df.at[i,\"mention text (just a few words around the trigger)\"] = df.at[i,\"mention text (just a few words around the trigger)\"].replace(triggerText, \"<t>\" + triggerText + \"</t>\")\n",
    "\n",
    "# # assign numerical labels\n",
    "# num_of_labels = len(list(set(df[annotations_column])))\n",
    "# if num_of_labels == 2:\n",
    "#     df['label'] = np.array([1 if x == \"b\" else 0 for x in df['annotation: b (belief or attitude), n (not a belief and not an attitude)']])\n",
    "# else:\n",
    "#     print(f\"Wrong number of labels: {number_of_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labels = open('data/classes.txt').read().splitlines()\n",
    "df = pd.read_csv(\"data/belief_benchmark.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also use of chemicals and machinery on their p...</td>\n",
       "      <td>NEGATIVE, NEGATIVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sources believe that twenty-five to 30 percent...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although these government-led initiatives are ...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In other projects of this kind, it is not alwa...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Many African policy makers evidently believe t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           sentiment  \\\n",
       "0  Also use of chemicals and machinery on their p...  NEGATIVE, NEGATIVE   \n",
       "1  Sources believe that twenty-five to 30 percent...        UNDETERMINED   \n",
       "2  Although these government-led initiatives are ...        UNDETERMINED   \n",
       "3  In other projects of this kind, it is not alwa...            POSITIVE   \n",
       "4  Many African policy makers evidently believe t...            POSITIVE   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_name = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "# NOTE: for cross validation, the model should be initialized inside the cv loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_true = eval_pred.label_ids\n",
    "    y_pred = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    report = metrics.classification_report(y_true, y_pred)\n",
    "    print(\"report: \\n\", report)\n",
    "    \n",
    "    print(\"rep type: \", type(report))\n",
    "    \n",
    "\n",
    "    return {'f1':metrics.f1_score(y_true, y_pred, average=\"macro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: not used right now, but can be\n",
    "# https://github.com/huggingface/transformers/blob/65659a29cf5a079842e61a63d57fa24474288998/src/transformers/models/bert/modeling_bert.py#L1486\n",
    "\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        cls_outputs = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_outputs = self.dropout(cls_outputs)\n",
    "        logits = self.classifier(cls_outputs)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for creating cross-validation folds\n",
    "def get_sample_based_on_idx(data, indeces):\n",
    "    return data.iloc[indeces, :].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 in set(df[\"label\"]) and 1 in set(df[\"label\"]) and len(list(set(df[\"label\"]))) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use sentences as text; TODO: can add wrapping for trigger \n",
    "# df[\"text\"] = df[\"sentence\"]\n",
    "# # how much of the data to use (can limit number of debugging)\n",
    "# df = df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also use of chemicals and machinery on their p...</td>\n",
       "      <td>NEGATIVE, NEGATIVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sources believe that twenty-five to 30 percent...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although these government-led initiatives are ...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In other projects of this kind, it is not alwa...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Many African policy makers evidently believe t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           sentiment  \\\n",
       "0  Also use of chemicals and machinery on their p...  NEGATIVE, NEGATIVE   \n",
       "1  Sources believe that twenty-five to 30 percent...        UNDETERMINED   \n",
       "2  Although these government-led initiatives are ...        UNDETERMINED   \n",
       "3  In other projects of this kind, it is not alwa...            POSITIVE   \n",
       "4  Many African policy makers evidently believe t...            POSITIVE   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just checking the df looks right\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparams\n",
    "num_epochs = 8\n",
    "batch_size = 6\n",
    "weight_decay = 0.01\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_triggerless\", # is this location in the tmp dir? \n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    weight_decay=weight_decay,\n",
    "    load_best_model_at_end=True, # this is supposed to make sure the best model is loaded by the trainer at the end\n",
    "    metric_for_best_model=\"eval_f1\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:  0\n",
      "LEN DF:  290\n",
      "done train df\n",
      "done eval df\n",
      "LEN EVAL:  73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351c90bbc25a45d19b568bb3faeab653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a40835a275342828e416b6ecf751325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e401296d1c2b45df978f18a80ad2cc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1866ed7bafe54533aaa4be41f121f46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.38      1.00      0.55        28\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.38        73\n",
      "   macro avg       0.10      0.25      0.14        73\n",
      "weighted avg       0.15      0.38      0.21        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2408273220062256, 'eval_f1': 0.1386138613861386, 'eval_runtime': 0.7064, 'eval_samples_per_second': 103.335, 'eval_steps_per_second': 18.402, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd0dd81db504199a949adfd73b967c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55        28\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.38        73\n",
      "   macro avg       0.10      0.25      0.14        73\n",
      "weighted avg       0.15      0.38      0.21        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.277237892150879, 'eval_f1': 0.1386138613861386, 'eval_runtime': 0.7535, 'eval_samples_per_second': 96.877, 'eval_steps_per_second': 17.252, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3268c22ac64e17929a2773a8816ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.38      1.00      0.55        28\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.38        73\n",
      "   macro avg       0.10      0.25      0.14        73\n",
      "weighted avg       0.15      0.38      0.21        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.3906382322311401, 'eval_f1': 0.1386138613861386, 'eval_runtime': 0.726, 'eval_samples_per_second': 100.551, 'eval_steps_per_second': 17.906, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3102c55bc0614e9aaf11e2c1c7781a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.43      0.59        28\n",
      "           1       0.50      0.45      0.48        11\n",
      "           2       0.55      0.96      0.70        28\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.60        73\n",
      "   macro avg       0.49      0.46      0.44        73\n",
      "weighted avg       0.64      0.60      0.57        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.3218382596969604, 'eval_f1': 0.44071375778692845, 'eval_runtime': 0.7141, 'eval_samples_per_second': 102.22, 'eval_steps_per_second': 18.204, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66df4b998f54913a4cd7ed5f81c3a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62        28\n",
      "           1       0.54      0.64      0.58        11\n",
      "           2       0.62      0.64      0.63        28\n",
      "           3       0.25      0.17      0.20         6\n",
      "\n",
      "    accuracy                           0.59        73\n",
      "   macro avg       0.51      0.51      0.51        73\n",
      "weighted avg       0.58      0.59      0.58        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.7004987001419067, 'eval_f1': 0.5082735247208933, 'eval_runtime': 0.7538, 'eval_samples_per_second': 96.837, 'eval_steps_per_second': 17.245, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff227d240924e61a62eef6343644363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60        28\n",
      "           1       0.46      0.55      0.50        11\n",
      "           2       0.62      0.64      0.63        28\n",
      "           3       0.17      0.17      0.17         6\n",
      "\n",
      "    accuracy                           0.56        73\n",
      "   macro avg       0.47      0.48      0.48        73\n",
      "weighted avg       0.57      0.56      0.56        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.9138838052749634, 'eval_f1': 0.47550479973518706, 'eval_runtime': 0.8086, 'eval_samples_per_second': 90.276, 'eval_steps_per_second': 16.076, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ea144ae52f4cdba03ac707686ec8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63        28\n",
      "           1       0.67      0.55      0.60        11\n",
      "           2       0.67      0.71      0.69        28\n",
      "           3       0.27      0.50      0.35         6\n",
      "\n",
      "    accuracy                           0.62        73\n",
      "   macro avg       0.58      0.58      0.57        73\n",
      "weighted avg       0.65      0.62      0.62        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.9840717315673828, 'eval_f1': 0.5675118323191346, 'eval_runtime': 0.7061, 'eval_samples_per_second': 103.389, 'eval_steps_per_second': 18.412, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5963710a2174a919fb5944d456bf61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63        28\n",
      "           1       0.60      0.55      0.57        11\n",
      "           2       0.69      0.64      0.67        28\n",
      "           3       0.27      0.50      0.35         6\n",
      "\n",
      "    accuracy                           0.60        73\n",
      "   macro avg       0.55      0.57      0.56        73\n",
      "weighted avg       0.63      0.60      0.61        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 2.1471667289733887, 'eval_f1': 0.5551665110488639, 'eval_runtime': 0.7131, 'eval_samples_per_second': 102.373, 'eval_steps_per_second': 18.231, 'epoch': 8.0}\n",
      "{'train_runtime': 129.3635, 'train_samples_per_second': 17.934, 'train_steps_per_second': 3.03, 'train_loss': 0.6210513601497728, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28161d5297614e9fa16edecfde2ef116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.57      0.63        28\n",
      "           1       0.67      0.55      0.60        11\n",
      "           2       0.67      0.71      0.69        28\n",
      "           3       0.27      0.50      0.35         6\n",
      "\n",
      "    accuracy                           0.62        73\n",
      "   macro avg       0.58      0.58      0.57        73\n",
      "weighted avg       0.65      0.62      0.62        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "F-1:  0.5675118323191346\n",
      "n of fasle pos: 7\n",
      "n of false neg: 21\n",
      "FOLD:  1\n",
      "LEN DF:  290\n",
      "done train df\n",
      "done eval df\n",
      "LEN EVAL:  73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cadd87d29c747b4a12eb45aaeb6f02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab216ba04df4931a941f71ca1ce5d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ec3dc73c07454bad4fbd084d392068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcc61bbcc5a4f1f81fa52cf0352211f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.34      1.00      0.51        25\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.34        73\n",
      "   macro avg       0.09      0.25      0.13        73\n",
      "weighted avg       0.12      0.34      0.17        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2598142623901367, 'eval_f1': 0.12755102040816327, 'eval_runtime': 0.6977, 'eval_samples_per_second': 104.623, 'eval_steps_per_second': 18.632, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7408202a0b764886ae9c63249d87d598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.50      0.37        26\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.33      0.36      0.35        25\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.30        73\n",
      "   macro avg       0.16      0.21      0.18        73\n",
      "weighted avg       0.22      0.30      0.25        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2366368770599365, 'eval_f1': 0.1780877573131094, 'eval_runtime': 0.6898, 'eval_samples_per_second': 105.834, 'eval_steps_per_second': 18.847, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2b1dc402bb43af9732406edd3a1c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.77      0.58        26\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.67      0.80      0.73        25\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.55        73\n",
      "   macro avg       0.28      0.39      0.33        73\n",
      "weighted avg       0.39      0.55      0.46        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.0288046598434448, 'eval_f1': 0.32674571805006586, 'eval_runtime': 0.698, 'eval_samples_per_second': 104.584, 'eval_steps_per_second': 18.625, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463ad393bd7c42119f14cc3cb4225d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56        26\n",
      "           1       0.75      0.30      0.43        20\n",
      "           2       0.54      0.88      0.67        25\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.58        73\n",
      "   macro avg       0.47      0.43      0.41        73\n",
      "weighted avg       0.60      0.58      0.55        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.1441408395767212, 'eval_f1': 0.4138095238095238, 'eval_runtime': 0.6958, 'eval_samples_per_second': 104.918, 'eval_steps_per_second': 18.684, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1df8d3120134172aee30111598cb1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64        26\n",
      "           1       0.57      0.65      0.60        20\n",
      "           2       0.82      0.72      0.77        25\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.66        73\n",
      "   macro avg       0.50      0.51      0.50        73\n",
      "weighted avg       0.66      0.66      0.66        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2062045335769653, 'eval_f1': 0.5030295108903682, 'eval_runtime': 0.7148, 'eval_samples_per_second': 102.124, 'eval_steps_per_second': 18.186, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a202243fa611437f9f26edcd69b25958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.27      0.35        26\n",
      "           1       0.62      0.50      0.56        20\n",
      "           2       0.57      0.92      0.71        25\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.55        73\n",
      "   macro avg       0.42      0.42      0.40        73\n",
      "weighted avg       0.55      0.55      0.52        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.9279017448425293, 'eval_f1': 0.4033119658119658, 'eval_runtime': 0.6883, 'eval_samples_per_second': 106.056, 'eval_steps_per_second': 18.887, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a225e833f54a778f040a9c1dab9bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43        26\n",
      "           1       0.50      0.50      0.50        20\n",
      "           2       0.68      0.76      0.72        25\n",
      "           3       0.20      0.50      0.29         2\n",
      "\n",
      "    accuracy                           0.55        73\n",
      "   macro avg       0.47      0.54      0.48        73\n",
      "weighted avg       0.55      0.55      0.55        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.800543189048767, 'eval_f1': 0.4843695066213524, 'eval_runtime': 0.6889, 'eval_samples_per_second': 105.966, 'eval_steps_per_second': 18.871, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37803edc13242b59db7288632154f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43        26\n",
      "           1       0.67      0.50      0.57        20\n",
      "           2       0.65      0.80      0.71        25\n",
      "           3       0.29      1.00      0.44         2\n",
      "\n",
      "    accuracy                           0.58        73\n",
      "   macro avg       0.52      0.67      0.54        73\n",
      "weighted avg       0.59      0.58      0.57        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.858216404914856, 'eval_f1': 0.5412353347135956, 'eval_runtime': 0.6883, 'eval_samples_per_second': 106.063, 'eval_steps_per_second': 18.888, 'epoch': 8.0}\n",
      "{'train_runtime': 123.3998, 'train_samples_per_second': 18.801, 'train_steps_per_second': 3.177, 'train_loss': 0.6376368464255819, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be6bd96e5144fef8e88e5b3aaa24570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43        26\n",
      "           1       0.67      0.50      0.57        20\n",
      "           2       0.65      0.80      0.71        25\n",
      "           3       0.29      1.00      0.44         2\n",
      "\n",
      "    accuracy                           0.58        73\n",
      "   macro avg       0.52      0.67      0.54        73\n",
      "weighted avg       0.59      0.58      0.57        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "F-1:  0.5412353347135956\n",
      "n of fasle pos: 10\n",
      "n of false neg: 21\n",
      "FOLD:  2\n",
      "LEN DF:  290\n",
      "done train df\n",
      "done eval df\n",
      "LEN EVAL:  73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf965d96a2d4bb2b144f8b45879c7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53312580f7334925bac9799e4b42e0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce00c2ae9734215b4a253fce7858949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbd4bcb218e4ff0a4665e8909823fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.60      0.43        20\n",
      "           1       1.00      0.08      0.15        12\n",
      "           2       0.67      0.77      0.72        31\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.51        73\n",
      "   macro avg       0.50      0.36      0.32        73\n",
      "weighted avg       0.54      0.51      0.45        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.146655559539795, 'eval_f1': 0.3247088732163359, 'eval_runtime': 0.6887, 'eval_samples_per_second': 105.998, 'eval_steps_per_second': 18.876, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032f3ae0b38145b8a8bd670070601c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.80      0.64        20\n",
      "           1       0.50      0.50      0.50        12\n",
      "           2       0.71      0.71      0.71        31\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.60        73\n",
      "   macro avg       0.44      0.50      0.46        73\n",
      "weighted avg       0.53      0.60      0.56        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.101973056793213, 'eval_f1': 0.4624193548387098, 'eval_runtime': 0.7585, 'eval_samples_per_second': 96.238, 'eval_steps_per_second': 17.138, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e891179f51457fb8a4d7db51eda5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62        20\n",
      "           1       0.71      0.42      0.53        12\n",
      "           2       0.61      0.87      0.72        31\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.62        73\n",
      "   macro avg       0.48      0.48      0.47        73\n",
      "weighted avg       0.54      0.62      0.56        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.3788487911224365, 'eval_f1': 0.4663408521303258, 'eval_runtime': 0.6881, 'eval_samples_per_second': 106.087, 'eval_steps_per_second': 18.892, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbdd58c23464aa99c8ce284b988a3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60        20\n",
      "           1       0.56      0.75      0.64        12\n",
      "           2       0.67      0.58      0.62        31\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.58        73\n",
      "   macro avg       0.43      0.52      0.47        73\n",
      "weighted avg       0.51      0.58      0.53        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 2.1076951026916504, 'eval_f1': 0.46588669950738915, 'eval_runtime': 0.6974, 'eval_samples_per_second': 104.674, 'eval_steps_per_second': 18.641, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfbeff5d37f45f08ff574f4cd9e5c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        20\n",
      "           1       0.70      0.58      0.64        12\n",
      "           2       0.75      0.87      0.81        31\n",
      "           3       0.20      0.10      0.13        10\n",
      "\n",
      "    accuracy                           0.70        73\n",
      "   macro avg       0.59      0.59      0.58        73\n",
      "weighted avg       0.66      0.70      0.67        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.606651782989502, 'eval_f1': 0.5843929702138658, 'eval_runtime': 0.6885, 'eval_samples_per_second': 106.026, 'eval_steps_per_second': 18.881, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bbc7e6f6b24a2595139a2cf1ffa3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70        20\n",
      "           1       0.78      0.58      0.67        12\n",
      "           2       0.74      0.84      0.79        31\n",
      "           3       0.33      0.30      0.32        10\n",
      "\n",
      "    accuracy                           0.68        73\n",
      "   macro avg       0.64      0.61      0.62        73\n",
      "weighted avg       0.68      0.68      0.68        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.6638725996017456, 'eval_f1': 0.6175837320574163, 'eval_runtime': 0.701, 'eval_samples_per_second': 104.136, 'eval_steps_per_second': 18.545, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6521c7fd1e0b492dbc264c2a80ec5cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       1.00      0.58      0.74        12\n",
      "           2       0.74      0.84      0.79        31\n",
      "           3       0.42      0.50      0.45        10\n",
      "\n",
      "    accuracy                           0.71        73\n",
      "   macro avg       0.72      0.66      0.67        73\n",
      "weighted avg       0.74      0.71      0.71        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.769463062286377, 'eval_f1': 0.6743037664090296, 'eval_runtime': 0.7044, 'eval_samples_per_second': 103.628, 'eval_steps_per_second': 18.454, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c56459fa8c0405d9f492918e021182e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       0.88      0.58      0.70        12\n",
      "           2       0.74      0.84      0.79        31\n",
      "           3       0.36      0.40      0.38        10\n",
      "\n",
      "    accuracy                           0.70        73\n",
      "   macro avg       0.68      0.63      0.65        73\n",
      "weighted avg       0.71      0.70      0.70        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.7695199251174927, 'eval_f1': 0.6466949716949717, 'eval_runtime': 0.7217, 'eval_samples_per_second': 101.151, 'eval_steps_per_second': 18.013, 'epoch': 8.0}\n",
      "{'train_runtime': 126.785, 'train_samples_per_second': 18.299, 'train_steps_per_second': 3.092, 'train_loss': 0.370776468393754, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25e917c40cc4a5ebaf9a8fcc9f79c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        20\n",
      "           1       1.00      0.58      0.74        12\n",
      "           2       0.74      0.84      0.79        31\n",
      "           3       0.42      0.50      0.45        10\n",
      "\n",
      "    accuracy                           0.71        73\n",
      "   macro avg       0.72      0.66      0.67        73\n",
      "weighted avg       0.74      0.71      0.71        73\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "F-1:  0.6743037664090296\n",
      "n of fasle pos: 5\n",
      "n of false neg: 16\n",
      "FOLD:  3\n",
      "LEN DF:  291\n",
      "done train df\n",
      "done eval df\n",
      "LEN EVAL:  72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fdfa6196fb473aba1a23b1a8cdf93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc4646ed23a453e800bb36df5cf7bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b028257d304eaba119f9ba0ac5c866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21143a544d66405784cedfd401b7f6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33        72\n",
      "   macro avg       0.08      0.25      0.12        72\n",
      "weighted avg       0.11      0.33      0.17        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2014882564544678, 'eval_f1': 0.125, 'eval_runtime': 0.7224, 'eval_samples_per_second': 99.673, 'eval_steps_per_second': 16.612, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ea70e84fd448f59bc642b9d89aff05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.46      1.00      0.63        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.46        72\n",
      "   macro avg       0.11      0.25      0.16        72\n",
      "weighted avg       0.21      0.46      0.29        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.1907284259796143, 'eval_f1': 0.15714285714285714, 'eval_runtime': 0.7311, 'eval_samples_per_second': 98.483, 'eval_steps_per_second': 16.414, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41159104880d40be9293bcd639d1be97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.46      1.00      0.63        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.46        72\n",
      "   macro avg       0.11      0.25      0.16        72\n",
      "weighted avg       0.21      0.46      0.29        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.1879019737243652, 'eval_f1': 0.15714285714285714, 'eval_runtime': 0.7386, 'eval_samples_per_second': 97.486, 'eval_steps_per_second': 16.248, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b35b1809dd24422bfddcf7cd054af33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.21      0.27        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.46      0.82      0.59        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.44        72\n",
      "   macro avg       0.21      0.26      0.21        72\n",
      "weighted avg       0.34      0.44      0.36        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.178407073020935, 'eval_f1': 0.2143066980023502, 'eval_runtime': 0.7304, 'eval_samples_per_second': 98.573, 'eval_steps_per_second': 16.429, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c452bd9187044b99b6d83ba5c423479a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.52      0.76      0.62        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.54        72\n",
      "   macro avg       0.28      0.34      0.30        72\n",
      "weighted avg       0.43      0.54      0.48        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2137031555175781, 'eval_f1': 0.3001543209876544, 'eval_runtime': 0.7293, 'eval_samples_per_second': 98.724, 'eval_steps_per_second': 16.454, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d793fe2f512341faa11952be89997e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.50      0.53        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.51      0.79      0.62        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.53        72\n",
      "   macro avg       0.27      0.32      0.29        72\n",
      "weighted avg       0.42      0.53      0.46        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.3066545724868774, 'eval_f1': 0.28809523809523807, 'eval_runtime': 0.7366, 'eval_samples_per_second': 97.743, 'eval_steps_per_second': 16.291, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af141e8a1a4f4ee68a0730633fde3a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.55      0.73      0.62        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.56        72\n",
      "   macro avg       0.28      0.35      0.31        72\n",
      "weighted avg       0.44      0.56      0.49        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.4649862051010132, 'eval_f1': 0.30969030969030964, 'eval_runtime': 0.7298, 'eval_samples_per_second': 98.657, 'eval_steps_per_second': 16.443, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8725f08c73844a1086c0a1c1b5882f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.50      0.82      0.62        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.51        72\n",
      "   macro avg       0.26      0.31      0.27        72\n",
      "weighted avg       0.41      0.51      0.44        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.4191663265228271, 'eval_f1': 0.2742200328407225, 'eval_runtime': 0.7376, 'eval_samples_per_second': 97.613, 'eval_steps_per_second': 16.269, 'epoch': 8.0}\n",
      "{'train_runtime': 124.7663, 'train_samples_per_second': 18.659, 'train_steps_per_second': 3.142, 'train_loss': 1.0912777647680165, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a78bedf0c64ea7bc8d916272479807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.55      0.73      0.62        33\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.56        72\n",
      "   macro avg       0.28      0.35      0.31        72\n",
      "weighted avg       0.44      0.56      0.49        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "F-1:  0.30969030969030964\n",
      "n of fasle pos: 12\n",
      "n of false neg: 20\n",
      "FOLD:  4\n",
      "LEN DF:  291\n",
      "done train df\n",
      "done eval df\n",
      "LEN EVAL:  72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e8d704f60f4aaa9eb03a69e5fb74c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/291 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe8b42a6bd645febe69b9491ec8e747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6baa834c45c2442c86e4f7b70423eea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909b3dad041f40f89f15c03782855159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.92      0.50        24\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.75      0.20      0.32        30\n",
      "           3       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.39        72\n",
      "   macro avg       0.27      0.28      0.20        72\n",
      "weighted avg       0.43      0.39      0.30        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2469133138656616, 'eval_f1': 0.20394736842105265, 'eval_runtime': 0.6006, 'eval_samples_per_second': 119.887, 'eval_steps_per_second': 19.981, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f567f96cb9674eeab8fdfd7729adbe8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.21      0.25        24\n",
      "           1       1.00      0.09      0.17        11\n",
      "           2       0.53      0.97      0.68        30\n",
      "           3       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.49        72\n",
      "   macro avg       0.46      0.32      0.27        72\n",
      "weighted avg       0.48      0.49      0.39        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.1272062063217163, 'eval_f1': 0.2747549019607843, 'eval_runtime': 0.6006, 'eval_samples_per_second': 119.874, 'eval_steps_per_second': 19.979, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51010dfaad84269b3c6c2a4db33975e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        24\n",
      "           1       0.57      0.73      0.64        11\n",
      "           2       0.75      0.90      0.82        30\n",
      "           3       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.68        72\n",
      "   macro avg       0.49      0.55      0.52        72\n",
      "weighted avg       0.61      0.68      0.64        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 0.8494635820388794, 'eval_f1': 0.5167193675889329, 'eval_runtime': 0.6084, 'eval_samples_per_second': 118.345, 'eval_steps_per_second': 19.724, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749e6f34591b4d32a6c21b687f3e96b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\conni\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.83      0.68        24\n",
      "           1       0.71      0.45      0.56        11\n",
      "           2       0.73      0.73      0.73        30\n",
      "           3       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.65        72\n",
      "   macro avg       0.50      0.51      0.49        72\n",
      "weighted avg       0.61      0.65      0.62        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 0.9700257778167725, 'eval_f1': 0.491713747645951, 'eval_runtime': 0.6018, 'eval_samples_per_second': 119.64, 'eval_steps_per_second': 19.94, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c96e1f53b2f4f67b588f5696aca7379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64        24\n",
      "           1       0.53      0.73      0.62        11\n",
      "           2       0.72      0.77      0.74        30\n",
      "           3       0.50      0.14      0.22         7\n",
      "\n",
      "    accuracy                           0.65        72\n",
      "   macro avg       0.60      0.57      0.55        72\n",
      "weighted avg       0.65      0.65      0.64        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.0627367496490479, 'eval_f1': 0.5544600484545577, 'eval_runtime': 0.6094, 'eval_samples_per_second': 118.15, 'eval_steps_per_second': 19.692, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffcac18a3bc45ccaaee353c134205c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68        24\n",
      "           1       0.67      0.73      0.70        11\n",
      "           2       0.81      0.73      0.77        30\n",
      "           3       0.43      0.43      0.43         7\n",
      "\n",
      "    accuracy                           0.69        72\n",
      "   macro avg       0.64      0.65      0.64        72\n",
      "weighted avg       0.70      0.69      0.70        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.1141154766082764, 'eval_f1': 0.6440383567614688, 'eval_runtime': 0.598, 'eval_samples_per_second': 120.398, 'eval_steps_per_second': 20.066, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4017874ce6400eae9505c6845b88e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75        24\n",
      "           1       0.67      0.73      0.70        11\n",
      "           2       0.85      0.73      0.79        30\n",
      "           3       0.60      0.43      0.50         7\n",
      "\n",
      "    accuracy                           0.74        72\n",
      "   macro avg       0.70      0.68      0.68        72\n",
      "weighted avg       0.74      0.74      0.73        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2270758152008057, 'eval_f1': 0.6840208601898512, 'eval_runtime': 0.6165, 'eval_samples_per_second': 116.781, 'eval_steps_per_second': 19.463, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a2767475cc4a77b956d01499dc38bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64        24\n",
      "           1       0.69      0.82      0.75        11\n",
      "           2       0.76      0.73      0.75        30\n",
      "           3       0.43      0.43      0.43         7\n",
      "\n",
      "    accuracy                           0.68        72\n",
      "   macro avg       0.63      0.65      0.64        72\n",
      "weighted avg       0.68      0.68      0.68        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "{'eval_loss': 1.2186124324798584, 'eval_f1': 0.6406580031940653, 'eval_runtime': 0.5945, 'eval_samples_per_second': 121.119, 'eval_steps_per_second': 20.186, 'epoch': 8.0}\n",
      "{'train_runtime': 124.9582, 'train_samples_per_second': 18.63, 'train_steps_per_second': 3.137, 'train_loss': 0.541894328837492, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae90a29a85c449648331b0688d910c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75        24\n",
      "           1       0.67      0.73      0.70        11\n",
      "           2       0.85      0.73      0.79        30\n",
      "           3       0.60      0.43      0.50         7\n",
      "\n",
      "    accuracy                           0.74        72\n",
      "   macro avg       0.70      0.68      0.68        72\n",
      "weighted avg       0.74      0.74      0.73        72\n",
      "\n",
      "rep type:  <class 'str'>\n",
      "F-1:  0.6840208601898512\n",
      "n of fasle pos: 9\n",
      "n of false neg: 10\n"
     ]
    }
   ],
   "source": [
    "output = open(\"original.txt\", \"a\")\n",
    "\n",
    "fold = 0\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for train_df_idx, eval_df_idx in kfold.split(df):\n",
    "    \n",
    "    print(\"FOLD: \", fold)\n",
    "    output.write(f\"FOLD: {fold}\\n\")\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    train_df = get_sample_based_on_idx(df, train_df_idx)\n",
    "    print(\"LEN DF: \", len(train_df))\n",
    "    output.write(f\"LEN DF: {len(train_df)}\\n\")\n",
    "#     train_df['label'] = [int(item) for item in train_df[\"annotation: b (belief or attitude), n (not a belief and not an attitude)\"]]\n",
    "    print(\"done train df\")\n",
    "    output.write(\"done train df\\n\")\n",
    "    eval_df = get_sample_based_on_idx(df, eval_df_idx)\n",
    "#     eval_df[\"label\"] = [int(item) for item in eval_df['annotation: b (belief or attitude), n (not a belief and not an attitude)']]\n",
    "    print(\"done eval df\")\n",
    "    output.write(\"done eval df\\n\")\n",
    "    print(\"LEN EVAL: \", len(eval_df))\n",
    "    output.write(f\"LEN EVAL: {len(eval_df)}\\n\")\n",
    "#     print(eval_df.head())\n",
    "    ds = DatasetDict()\n",
    "    ds['train'] = Dataset.from_pandas(train_df)\n",
    "    ds['validation'] = Dataset.from_pandas(eval_df)\n",
    "    train_ds = ds['train'].map(\n",
    "        tokenize, batched=True,\n",
    "        # remove_columns=['index', 'sentence', 'trigger', 'annotation: b (belief or attitude), n (not a belief and not an attitude)', 'paragraph'],\n",
    "    )\n",
    "    eval_ds = ds['validation'].map(\n",
    "        tokenize,\n",
    "        batched=True,\n",
    "        # remove_columns=['index', 'sentence', 'trigger', 'annotation: b (belief or attitude), n (not a belief and not an attitude)', 'paragraph'],\n",
    "    )\n",
    "\n",
    "#     config = AutoConfig.from_pretrained(\n",
    "#         transformer_name,\n",
    "#         num_labels=2,\n",
    "#     )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(transformer_name, num_labels=4)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "#     model = (\n",
    "#         BertForSequenceClassification\n",
    "#         .from_pretrained(transformer_name, config=config)\n",
    "#     )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    trainer.train()\n",
    "    # after training, predict (will use best model?)\n",
    "    preds = trainer.predict(eval_ds)\n",
    "#     print(\"HERE: \" , preds)\n",
    "    final_preds = [np.argmax(x) for x in preds.predictions]\n",
    "    real_f1 = metrics.f1_score(final_preds, eval_df[\"label\"], average=\"macro\")\n",
    "    print(\"F-1: \", real_f1)\n",
    "    output.write(f\"F-1: {real_f1}\\n\")\n",
    "    model_name = f\"{transformer_name}-best-of-fold-{fold}-f1-{real_f1}\"\n",
    "    model_dir = os.path.join(models_dir, model_name)\n",
    "\n",
    "    trainer.save_model(model_dir)\n",
    "    count_f_n = 0\n",
    "    count_f_p = 0\n",
    "    for i, item in enumerate(final_preds):\n",
    "        if not item == eval_ds[\"label\"][i]:\n",
    "            false_df = pd.DataFrame()\n",
    "            false_df[\"text\"] = [eval_df[\"text\"][i]]\n",
    "            false_df[\"real\"] = [eval_df[\"label\"][i]]\n",
    "            false_df[\"predicted\"] = [item]\n",
    "            new_df = pd.concat([new_df, false_df])\n",
    "#             print(\"NEW: \\n\", false_df.head())\n",
    "            if item == 0:\n",
    "                count_f_n += 1\n",
    "\n",
    "            else:\n",
    "                count_f_p += 1\n",
    "#                 print(eval_ds[\"sentence\"][i], \" \" , eval_ds[\"label\"][i], \" \", item, \"\\n\")\n",
    "\n",
    "    #     else:\n",
    "    #         print(\">>>\", list(X_test)[i], \" \" , y_test_enc[i], \" \", list(y_test)[i], \" \", item, \"\\n\")\n",
    "    print(f\"n of fasle pos: {count_f_n}\")\n",
    "    output.write(f\"n of fasle pos: {count_f_n}\\n\")\n",
    "    print(f\"n of false neg: {count_f_p}\")\n",
    "    output.write(f\"n of false neg: {count_f_p}\\n\")\n",
    "    \n",
    "    \n",
    "#     print(new_df.head())\n",
    "    new_df.to_csv(os.path.join(models_dir, \"false_annotations_\" + str(fold) + \".tsv\"), sep=\"\\t\")  \n",
    "    fold += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "output.write(\"{torch.cuda.memory_summary(device=None, abbreviated=False)}\")\n",
    "\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
