{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    device =  -1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"bert-base-cased\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also use of chemicals and machinery on their p...</td>\n",
       "      <td>NEGATIVE, NEGATIVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sources believe that twenty-five to 30 percent...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although these government-led initiatives are ...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In other projects of this kind, it is not alwa...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Many African policy makers evidently believe t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Similar initiatives have and can be initiated ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Collective sales account for an average of 64 ...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Individual sales account for slightly lower vo...</td>\n",
       "      <td>UNDETERMINED, UNDETERMINED, UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Modernization of the rice value chain The VC t...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Small-scale processors use mills to husk the r...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Also use of chemicals and machinery on their p...   \n",
       "1    Sources believe that twenty-five to 30 percent...   \n",
       "2    Although these government-led initiatives are ...   \n",
       "3    In other projects of this kind, it is not alwa...   \n",
       "4    Many African policy makers evidently believe t...   \n",
       "..                                                 ...   \n",
       "358  Similar initiatives have and can be initiated ...   \n",
       "359  Collective sales account for an average of 64 ...   \n",
       "360  Individual sales account for slightly lower vo...   \n",
       "361  Modernization of the rice value chain The VC t...   \n",
       "362  Small-scale processors use mills to husk the r...   \n",
       "\n",
       "                                    sentiment  label  \n",
       "0                          NEGATIVE, NEGATIVE      1  \n",
       "1                                UNDETERMINED      0  \n",
       "2                                UNDETERMINED      0  \n",
       "3                                    POSITIVE      2  \n",
       "4                                    POSITIVE      2  \n",
       "..                                        ...    ...  \n",
       "358                                  POSITIVE      2  \n",
       "359                              UNDETERMINED      0  \n",
       "360  UNDETERMINED, UNDETERMINED, UNDETERMINED      0  \n",
       "361                              UNDETERMINED      0  \n",
       "362                              UNDETERMINED      0  \n",
       "\n",
       "[363 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labels = open('data/classes.txt').read().splitlines()\n",
    "all_df = pd.read_csv(\"data/belief_benchmark.csv\")\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'sentiment', 'label'],\n",
       "    num_rows: 363\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(all_df)\n",
    "#dataset.save_to_disk(\"data/belief_dataset\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "transformer_name = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18a5fc410d740f482106202c18d8936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "holdout_df = df = pd.read_csv(\"data/belief_benchmark_holdout.csv\")\n",
    "holdout_ds = Dataset.from_pandas(holdout_df)\n",
    "holdout_ds = holdout_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ab0ab72df247b08d5e84325b1d7004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8248ecffbdb44b98b39020596ba05a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "labels = [\"neither\", \"negative\", \"positive\", \"both\"]\n",
    "pred_i_list = []\n",
    "for pred in tqdm(classifier(KeyDataset(dataset, \"text\"), batch_size=6, candidate_labels=labels)):\n",
    "    pred_i = labels.index(pred[\"labels\"][0])\n",
    "    pred_i_list.append(pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neither       0.38      0.63      0.47       122\n",
      "    negative       0.08      0.09      0.09        65\n",
      "    positive       0.33      0.06      0.10       147\n",
      "        both       0.05      0.10      0.07        29\n",
      "\n",
      "    accuracy                           0.26       363\n",
      "   macro avg       0.21      0.22      0.18       363\n",
      "weighted avg       0.28      0.26      0.22       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = dataset[\"label\"]\n",
    "y_pred = pred_i_list\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [1, 0, 0, 2, 2, 3, 1, 0, 3, 2, 2, 2, 1, 2, 0, 1, 1, 2, 0, 3, 3, 0, 2, 2, 1, 2, 2, 2, 1, 2, 3, 0, 2, 0, 2, 2, 2, 3, 1, 0, 2, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 2, 3, 2, 2, 2, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 0, 3, 1, 0, 0, 2, 0, 2, 3, 2, 2, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 0, 2, 3, 0, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 1, 0, 1, 1, 0, 2, 0, 0, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 2, 0, 2, 2, 2, 1, 3, 0, 3, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 2, 0, 2, 2, 1, 3, 2, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 3, 3, 0, 3, 0, 0, 0, 0, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 3, 2, 2, 0, 2, 3, 2, 2, 0, 1, 2, 0, 2, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 3, 0, 2, 0, 0, 1, 0, 0, 2, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 1, 3, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 3, 0, 3, 3, 3, 2, 0, 0, 2, 2, 0, 1, 1, 2, 2, 2, 0, 0, 0, 0]\n",
      "y_pred: [0, 1, 3, 0, 0, 3, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 3, 0, 0, 1, 3, 0, 3, 1, 1, 1, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 0, 1, 1, 0, 1, 0, 3, 0, 0, 0, 0, 0, 3, 1, 3, 0, 0, 3, 1, 3, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 0, 0, 3, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 3, 1, 1, 1, 2, 0, 0, 2, 2, 2, 1, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 1, 1, 0, 3, 3, 0, 3, 0, 3, 0, 1, 2, 0, 0, 1, 3, 1, 0, 1, 3, 3, 0, 0, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 3, 0, 3, 1, 0, 1, 1, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 1, 2, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 3, 3, 0, 0, 0, 1, 0, 1, 0, 1, 3, 3, 3, 2, 0, 1, 3, 1, 1, 1, 1, 2, 3, 0, 2, 0, 0, 2, 2, 0, 0, 3, 2, 1, 0, 2, 3, 3, 0, 0, 1, 0, 1, 3, 0, 3, 0, 3, 1, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 1, 1, 0, 3, 0, 3, 3, 0, 1, 0, 3, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 1, 3, 3, 0, 0, 3, 2, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_true: {y_true}\")\n",
    "print(f\"y_pred: {y_pred}\")\n",
    "import pickle\n",
    "pickle.dump(y_pred, open(f\"few_shot_results/y_pred_zero_all\", \"wb\"))\n",
    "pickle.dump(y_true, open(f\"few_shot_results/y_true_zero_all\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
