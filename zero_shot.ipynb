{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    device =  -1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify transformer name\n",
    "# used to load pipeline and tokenizer\n",
    "transformer_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "# load pipeline\n",
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=transformer_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also use of chemicals and machinery on their p...</td>\n",
       "      <td>NEGATIVE, NEGATIVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sources believe that twenty-five to 30 percent...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Although these government-led initiatives are ...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In other projects of this kind, it is not alwa...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Many African policy makers evidently believe t...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Similar initiatives have and can be initiated ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Collective sales account for an average of 64 ...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Individual sales account for slightly lower vo...</td>\n",
       "      <td>UNDETERMINED, UNDETERMINED, UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Modernization of the rice value chain The VC t...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Small-scale processors use mills to husk the r...</td>\n",
       "      <td>UNDETERMINED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Also use of chemicals and machinery on their p...   \n",
       "1    Sources believe that twenty-five to 30 percent...   \n",
       "2    Although these government-led initiatives are ...   \n",
       "3    In other projects of this kind, it is not alwa...   \n",
       "4    Many African policy makers evidently believe t...   \n",
       "..                                                 ...   \n",
       "358  Similar initiatives have and can be initiated ...   \n",
       "359  Collective sales account for an average of 64 ...   \n",
       "360  Individual sales account for slightly lower vo...   \n",
       "361  Modernization of the rice value chain The VC t...   \n",
       "362  Small-scale processors use mills to husk the r...   \n",
       "\n",
       "                                    sentiment  label  \n",
       "0                          NEGATIVE, NEGATIVE      1  \n",
       "1                                UNDETERMINED      0  \n",
       "2                                UNDETERMINED      0  \n",
       "3                                    POSITIVE      2  \n",
       "4                                    POSITIVE      2  \n",
       "..                                        ...    ...  \n",
       "358                                  POSITIVE      2  \n",
       "359                              UNDETERMINED      0  \n",
       "360  UNDETERMINED, UNDETERMINED, UNDETERMINED      0  \n",
       "361                              UNDETERMINED      0  \n",
       "362                              UNDETERMINED      0  \n",
       "\n",
       "[363 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all data\n",
    "import pandas as pd\n",
    "labels = open('data/classes.txt').read().splitlines()\n",
    "all_df = pd.read_csv(\"data/belief_benchmark.csv\")\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee270d8f12ac408b9dc54e9558ef245d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create dataset from all data\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(all_df)\n",
    "#dataset.save_to_disk(\"data/belief_dataset\")\n",
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc370ee464145d3978ad2b8222cddf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load and create dataset from holdout data\n",
    "holdout_df = df = pd.read_csv(\"data/belief_benchmark_holdout.csv\")\n",
    "holdout_ds = Dataset.from_pandas(holdout_df)\n",
    "holdout_ds = holdout_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70870e8b6bbd4a9eba4a2d3121ea901e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run prediction and save predicted label as index into labels array\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "labels = [\"neither\", \"negative\", \"positive\", \"both\"]\n",
    "pred_i_list = []\n",
    "# use KeyDataset(dataset, ...) for results on all data\n",
    "# use KeyDataset(holdout_ds, ...) for results on holdout\n",
    "for pred in tqdm(classifier(KeyDataset(dataset, \"text\"), batch_size=6, candidate_labels=labels)):\n",
    "    pred_i = labels.index(pred[\"labels\"][0])\n",
    "    pred_i_list.append(pred_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neither       0.41      0.46      0.43       122\n",
      "    negative       0.21      0.32      0.25        65\n",
      "    positive       0.48      0.20      0.28       147\n",
      "        both       0.05      0.10      0.06        29\n",
      "\n",
      "    accuracy                           0.30       363\n",
      "   macro avg       0.29      0.27      0.26       363\n",
      "weighted avg       0.37      0.30      0.31       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = dataset[\"label\"]\n",
    "y_pred = pred_i_list\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true: [1, 0, 0, 2, 2, 3, 1, 0, 3, 2, 2, 2, 1, 2, 0, 1, 1, 2, 0, 3, 3, 0, 2, 2, 1, 2, 2, 2, 1, 2, 3, 0, 2, 0, 2, 2, 2, 3, 1, 0, 2, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 2, 3, 2, 2, 2, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 2, 2, 0, 0, 3, 1, 0, 0, 2, 0, 2, 3, 2, 2, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 0, 2, 1, 2, 0, 2, 2, 2, 0, 0, 2, 3, 0, 2, 0, 0, 0, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 1, 0, 1, 1, 0, 2, 0, 0, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 2, 0, 2, 2, 2, 1, 3, 0, 3, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 2, 0, 2, 2, 1, 3, 2, 2, 1, 0, 1, 1, 0, 2, 1, 2, 2, 3, 3, 0, 3, 0, 0, 0, 0, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 3, 2, 2, 0, 2, 3, 2, 2, 0, 1, 2, 0, 2, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 3, 0, 2, 0, 0, 1, 0, 0, 2, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 1, 3, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 3, 0, 3, 3, 3, 2, 0, 0, 2, 2, 0, 1, 1, 2, 2, 2, 0, 0, 0, 0]\n",
      "y_pred: [3, 0, 2, 3, 1, 1, 0, 0, 1, 0, 1, 0, 1, 2, 3, 0, 3, 0, 0, 0, 1, 0, 0, 1, 3, 3, 1, 1, 1, 0, 1, 1, 0, 3, 1, 0, 0, 3, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 3, 1, 2, 1, 1, 1, 0, 3, 3, 0, 3, 1, 0, 3, 0, 2, 1, 3, 2, 2, 3, 1, 1, 0, 1, 0, 1, 2, 2, 1, 2, 1, 2, 3, 0, 0, 0, 1, 0, 3, 3, 3, 1, 1, 2, 0, 0, 0, 2, 3, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 1, 1, 3, 3, 2, 1, 0, 2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 1, 1, 1, 3, 2, 1, 3, 1, 1, 0, 1, 1, 1, 3, 0, 0, 3, 2, 0, 2, 1, 0, 0, 3, 1, 2, 2, 0, 3, 0, 1, 0, 0, 3, 2, 3, 2, 2, 0, 0, 0, 1, 0, 2, 3, 2, 1, 2, 0, 3, 0, 0, 3, 3, 1, 2, 1, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 3, 3, 1, 1, 0, 3, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, 2, 2, 1, 0, 3, 2, 0, 3, 1, 2, 3, 1, 1, 3, 1, 3, 1, 0, 3, 0, 1, 2, 0, 0, 2, 1, 1, 1, 1, 3, 1, 1, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 3, 1, 0, 0, 0, 0, 2, 0, 0, 1, 2, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 2, 1, 3, 2, 1, 0, 2, 2, 0, 1, 0, 3, 2, 1, 1, 1, 0, 3, 0, 0, 2, 0, 1, 1, 3, 2, 3, 1, 2, 3, 0, 3, 1, 1, 0, 1, 3, 3, 0, 0, 1, 3, 1, 1, 1, 2, 0, 1, 0, 2, 1, 0, 1, 2, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# print true vs predicted label idxs, save lists as pickle\n",
    "print(f\"y_true: {y_true}\")\n",
    "print(f\"y_pred: {y_pred}\")\n",
    "import pickle\n",
    "pickle.dump(y_pred, open(f\"few_shot_results/y_pred_zero_all\", \"wb\"))\n",
    "pickle.dump(y_true, open(f\"few_shot_results/y_true_zero_all\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
